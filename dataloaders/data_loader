

def create_data_loaders(args):
    # Data loading code
    print("=> creating data loaders ...")
    traindir = os.path.join('/home2/yufei_dataset', args.data, 'train')
    valdir = os.path.join('/home2/yufei_dataset', args.data, 'val')
    train_loader = None
    val_loader = None

    # sparsifier is a class for generating random sparse depth input from the ground truth
    sparsifier = None
    max_depth = args.max_depth if args.max_depth >= 0.0 else np.inf
    if args.sparsifier == UniformSampling.name:
        sparsifier = UniformSampling(num_samples=args.num_samples, max_depth=max_depth)
    elif args.sparsifier == SimulatedStereo.name:
        sparsifier = SimulatedStereo(num_samples=args.num_samples, max_depth=max_depth)

    if args.data == 'nyudepthv2':
        from dataloaders.nyu_dataloader import NYUDataset
        if True:
            train_dataset = NYUDataset(traindir,
                                       type='train',
                                       modality=args.modality,
                                       sparsifier=sparsifier)
        else:
            val_dataset = NYUDataset(valdir,
                                     type='val',
                                     modality=args.modality,
                                     sparsifier=sparsifier)

    elif args.data == 'kitti':
        from dataloaders.kitti_dataloader import KITTIDataset
        if not args.evaluate:
            train_dataset = KITTIDataset(traindir,
                                         type='train',
                                         modality=args.modality,
                                         sparsifier=sparsifier)
        else:
            val_dataset = KITTIDataset(valdir,
                                       type='val',
                                       modality=args.modality,
                                       sparsifier=sparsifier)

    else:
        raise RuntimeError('Dataset not found.' +
                           'The dataset must be either of nyudepthv2 or kitti.')

    # put construction of train loader here, for those who are interested in testing only
    if True:
        train_loader = torch.utils.data.DataLoader(train_dataset,
                                                   batch_size=args.batch_size,
                                                   shuffle=True,
                                                   num_workers=args.workers,
                                                   pin_memory=True, sampler=None,
                                                   worker_init_fn=lambda work_id:np.random.seed(work_id))
    else:
        val_loader = torch.utils.data.DataLoader(val_dataset,
                                                 batch_size=1,      # set batch size to be 1 for validation
                                                 shuffle=False,
                                                 num_workers=args.workers,
                                                 pin_memory=True)

    print("=> data loaders created.")
    return train_loader, val_loader
